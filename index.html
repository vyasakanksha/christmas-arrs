<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, viewport-fit=cover"
    />
    <title>Happy Christmas</title>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.2/dist/mindar-image.prod.js"></script>
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.2/dist/mindar-image-aframe.prod.js"></script>

    <style>
      html,
      body {
        margin: 0;
        padding: 0;
        height: 100%;
        width: 100%;
        overflow: hidden;
        background: #000;
      }

      #tapToStart {
        position: fixed;
        inset: 0;
        display: grid;
        place-items: center;
        background: rgba(0, 0, 0, 0.65);
        color: #fff;
        font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial;
        text-align: center;
        padding: 24px;
        z-index: 9999;
      }

      #tapToStart button {
        font-size: 18px;
        padding: 14px 18px;
        border-radius: 12px;
        border: 0;
        cursor: pointer;
        background: #fff;
        color: #000;
      }

      #hint {
        margin-top: 14px;
        opacity: 0.85;
        font-size: 14px;
        line-height: 1.4;
      }
    </style>
  </head>

  <body>
    <!-- iOS/Chrome often require a user gesture before video w/ audio can play.
         This overlay provides that "tap" gesture. -->
    <div id="tapToStart">
      <div>
        <button id="startBtn">Tap to start</button>
      </div>
    </div>

    <!-- AR Scene - shows camera feed -->
    <a-scene
      id="arScene"
      mindar-image="imageTargetSrc: ./targets.mind;"
      color-space="sRGB"
      embedded
      renderer="colorManagement: true, physicallyCorrectLights"
      vr-mode-ui="enabled: false"
      device-orientation-permission-ui="enabled: false"
    >
      <a-assets>
        <video
          id="vid"
          src="./video.mp4"
          preload="auto"
          loop
          playsinline
          webkit-playsinline
          crossorigin="anonymous"
        ></video>
      </a-assets>

      <a-camera
        id="camera"
        position="0 0 0"
        look-controls="enabled: false"
        wasd-controls="enabled: false"
      ></a-camera>

      <a-entity mindar-image-target="targetIndex: 0">
        <a-video
          id="arVideo"
          src="#vid"
          position="0 0 0"
          rotation="0 0 0"
          width="1.5"
          height="1"
          autoplay
          loop
        ></a-video>
      </a-entity>
    </a-scene>

    <script>
      const startOverlay = document.getElementById("tapToStart");
      const startBtn = document.getElementById("startBtn");
      const arScene = document.getElementById("arScene");
      const video = document.getElementById("vid");

      let userEnabledPlayback = false;
      let arSystem = null;

      // User gesture: unlock playback on iOS
      startBtn.addEventListener("click", async () => {
        userEnabledPlayback = true;
        startOverlay.style.display = "none";

        // Start AR system
        arSystem = arScene.systems["mindar-image-system"];

        // Wait for AR system to be ready
        arScene.addEventListener("arReady", () => {
          console.log("AR system ready");
        });

        // Listen for target found event
        arScene.addEventListener("targetFound", (event) => {
          console.log("Target found!");

          // Ensure the video asset is unmuted and playing
          if (video) {
            video.muted = false;
            video.play().catch((e) => {
              console.log("Video play failed:", e);
            });
          }

          // Also try to access the video through the a-video component
          setTimeout(() => {
            const arVideoEl = document.getElementById("arVideo");
            if (arVideoEl) {
              // A-Frame stores the video element in the material component
              const material = arVideoEl.components?.material;
              if (material && material.material && material.material.map) {
                const videoTexture = material.material.map;
                if (
                  videoTexture.image &&
                  videoTexture.image.tagName === "VIDEO"
                ) {
                  const videoEl = videoTexture.image;
                  videoEl.muted = false;
                  videoEl.play().catch((e) => {
                    console.log("AR video element play failed:", e);
                  });
                }
              }
            }
          }, 100);
        });

        // Listen for target lost event
        arScene.addEventListener("targetLost", () => {
          console.log("Target lost!");
          // Pause video when target is lost
          if (video) {
            video.pause();
          }
        });

        // Start AR
        await arSystem.start();
      });

      // Ensure video is unmuted when user enables playback
      arScene.addEventListener("loaded", () => {
        if (userEnabledPlayback && video) {
          video.muted = false;
        }
      });
    </script>
  </body>
</html>
